dataset: 'h36m'
t_his: 25
t_pred: 100
batch_size: 256
num_epoch: 501
milestone: [50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500]
num_data_sample: 50000
num_val_data_sample: 5000
lr: 6.e-4
n_pre: 25
multimodal_path: ./data/data_multi_modal/t_his25_1_thre0.500_t_pred100_thre0.100_filtered_dlow.npz
data_candi_path: ./data/data_multi_modal/data_candi_t_his25_t_pred100_skiprate20.npz
padding: 'LastFrame'
num_layers: 5
num_heads: 8
latent_dims: 512
dropout: 0.2
mod_train: 0.5
mod_test: 1.0
cfg_scale: 1.0
use_dct: True
dct_norm_enable: False
resume: False
ckpt_path: ""
frame_mask: False
joint_mask: False
residual_data: False
random_sample: False
cross_attention: False
stylization_block: False
flash_attention: True
se_layer: False
skip_type: 'concat'
model_name: 'MotioniTransformer'